{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Black positivity\n",
    "### News article scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notebook for collecting Black news articles from positive good black news and connecting to newsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Import and remember to have your news api key set as en environment variable\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv C:/PATH/TO/API/KEY.env\n",
    "    \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from pprint import pprint as pp\n",
    "from nytimesarticle import articleAPI\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce\n",
    "from newsapi import NewsApiClient\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import sqlite3\n",
    "import time\n",
    "import re \n",
    "import requests\n",
    "import matplotlib.pyplot\n",
    "import psycopg2\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading api key and setting to variable 'newsapi'\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "newsapi = NewsApiClient(api_key=  api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def article_grab(url,name ):\n",
    "    \"\"\" Function to take a url form goodblack news and return a dataframe of headlines\"\"\"\n",
    "    wd = webdriver.Chrome()\n",
    "    time.sleep(5)\n",
    "    wd.get(url)\n",
    "    while True:\n",
    "        try:\n",
    "            python_button = wd.find_elements_by_xpath('//*[@id=\"infinite-handle\"]/span/button')[0]\n",
    "            time.sleep(2)\n",
    "            python_button.click()\n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    \n",
    "    time.sleep(10)\n",
    "    \n",
    "    ids = wd.find_elements_by_xpath('//*[contains(@id,\"post-\")]')\n",
    "    \n",
    "    print('got elements')\n",
    "\n",
    "    comment_ids = []\n",
    "    \n",
    "    for i in ids:\n",
    "        \n",
    "        comment_ids.append(i.get_attribute('id'))\n",
    "    \n",
    "    regex = re.compile('.*like')\n",
    "    \n",
    "    filtered = [i for i in comment_ids if not regex.search(i)]\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['user_id'])####\n",
    "    \n",
    "    print('gotdf')\n",
    "    \n",
    "    for title in filtered:\n",
    "        try:\n",
    "            userid_element = wd.find_elements_by_xpath('//*[@id=\"' + title + '\"]/header/div/div/a/h1')[0]\n",
    "            time.sleep(5)\n",
    "            userid = userid_element.text\n",
    "            df.loc[len(df)] = [userid]\n",
    "            print(userid)\n",
    "        except:\n",
    "            print('dfadded')\n",
    "            continue\n",
    "    print('close')\n",
    "    wd.close()\n",
    "    df.to_csv(str(name) + '.csv')\n",
    "    print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv_newapi(result):\n",
    "    article_dict={\n",
    "    'source':[],\n",
    "    'title':[]#,\n",
    "#    'category':[]\n",
    "    }\n",
    "\n",
    "    for i in range(len(result['articles'])):\n",
    "    \n",
    "        article_dict['source'].append(result['articles'][i]['source']['name'])\n",
    "        article_dict['title'].append(result['articles'][i]['title'])\n",
    " #       article_dict['category'] = cat_list.values\n",
    "        global articledf    \n",
    "        articledf = pd.DataFrame(article_dict)\n",
    "    return articledf\n",
    "def get_articles(cat, query):\n",
    "    \n",
    "    catdict = newsapi.get_sources(category = cat)\n",
    "    sources = catdict['sources']\n",
    "    source_list = []\n",
    "    #cat_list = list([cat] * 100)\n",
    "    #print(cat_list)\n",
    "    df_list = []\n",
    "                                      \n",
    "    for example in sources:\n",
    "        if example['language'] == 'en':\n",
    "            source_list.append(example['id'])\n",
    "        else:\n",
    "            pass\n",
    "                                \n",
    "    for source in source_list:\n",
    "        cat_article = newsapi.get_everything(q=query,\n",
    "                            page_size = 100,\n",
    "                            sort_by='relevancy',\n",
    "                            sources = source,\n",
    "                            language='en')\n",
    "#         n_results = len(cat_article['articles'])\n",
    "#         cat_list = list([cat] * n_results)\n",
    "#         print(n_results)\n",
    "#         cat_list = pd.Series(cat_list)\n",
    "#         print(cat_list)\n",
    "#         print(len(cat_list))\n",
    "        articledf = conv_newapi(cat_article)#, cat_list)\n",
    "        df_list.append(articledf)\n",
    "        df = pd.concat(df_list)\n",
    "        time.sleep(10)\n",
    "    return df\n",
    "        \n",
    "                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "goodblacknews scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url1 = 'https://goodblacknews.org/category/businessfinance/'\n",
    "url2 = 'https://goodblacknews.org/category/arts-style/'\n",
    "url3 = 'https://goodblacknews.org/category/entertainment-2/mediainternet/'\n",
    "url4 = 'https://goodblacknews.org/category/sports/'\n",
    "url5 = 'https://goodblacknews.org/category/lifestyle-2/'\n",
    "url6 = 'https://goodblacknews.org/category/books/'\n",
    "url7 = 'https://goodblacknews.org/category/education/'\n",
    "url8 = 'https://goodblacknews.org/category/technology/'\n",
    "url9 = 'https://goodblacknews.org/category/news/u-s/'\n",
    "url10 = 'https://goodblacknews.org/category/commemorations/'\n",
    "url11 = 'https://goodblacknews.org/category/international/'\n",
    "url12 = 'https://goodblacknews.org/category/politics/'\n",
    "\n",
    "article_grab(url1, 'biz')\n",
    "article_grab(url2, 'art')\n",
    "article_grab(url3, 'ent')\n",
    "article_grab(url4, 'sports')\n",
    "article_grab(url5, 'life')\n",
    "article_grab(url6, 'books')\n",
    "article_grab(url7, 'ed')\n",
    "article_grab(url8, 'tech')\n",
    "article_grab(url9, 'us')\n",
    "article_grab(url10, 'commemorations')\n",
    "article_grab(url11,'int')\n",
    "article_grab(url12,'pol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now to get news headlines from other sources using news api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Collecting articles from five categories using three search terms:\n",
    "bla_sports = get_articles('sports', 'black american')\n",
    "aa_sports = get_articles('sports', 'african american')\n",
    "black_americans_sports = get_articles('sports', 'black americans')\n",
    "bla_general = get_articles('general', 'black american')\n",
    "aa_gen = get_articles('general', 'african american')\n",
    "black_a_gen = get_articles('general', 'black americans')\n",
    "bl_biz = get_articles('business', 'black american')\n",
    "aa_biz = get_articles('business', 'black american')\n",
    "black_a_biz = get_articles('business', 'black american')\n",
    "bl_tech = get_articles('technology', 'black american')\n",
    "aa_tech = get_articles('technology', 'african american')\n",
    "black_aatech = get_articles('technology', 'black americans')\n",
    "bl_ent = get_articles('entertainment', 'black american')\n",
    "aa_ent = get_articles('entertainment', 'african american')\n",
    "black_ent = get_articles('entertainment', 'black americans')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Now concat and save as csv files\n",
    "\n",
    "blsportsdf = pd.concat(bla_sports, aa_sports, black_americans_sports)\n",
    "blgendf = pd.concat(black_a_gen, aa_gen, bla_general)\n",
    "blbizdf = pd.concat(bl_biz,aa_biz, black_a_biz)\n",
    "blsportsdf.to_csv('blsports.csv')\n",
    "blgendf.to_csv('blgen.csv')\n",
    "blbizdf.to_csv('blbiz.csv')\n",
    "tech = [bl_tech, aa_tech, black_aatech]\n",
    "bltech = pd.concat(tech)\n",
    "bltech.to_csv('bltech.csv')\n",
    "blent = pd.concat([bl_ent,aa_ent,black_ent])\n",
    "blent.to_csv('blent.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
